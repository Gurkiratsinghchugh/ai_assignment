import numpy as np


np.random.seed(0)
num_passengers = 1000


age = np.random.randint(1, 80, num_passengers)
fare = np.random.uniform(5, 300, num_passengers)
gender = np.random.randint(0, 2, num_passengers)


survived = np.random.randint(0, 2, num_passengers)


X = np.column_stack((age, fare, gender))


X = np.column_stack((np.ones(num_passengers), X))


y = survived.reshape(-1, 1)
def sigmoid(z):
    return 1 / (1 + np.exp(-z))

def predict(X, theta):
    return sigmoid(np.dot(X, theta))

def cost_function(X, y, theta):
    m = len(y)
    h = predict(X, theta)
    epsilon = 1e-5  
    cost = (-1 / m) * np.sum(y * np.log(h + epsilon) + (1 - y) * np.log(1 - h + epsilon))
    return cost

def gradient_descent(X, y, theta, alpha, num_iters):
    m = len(y)
    J_history = []

    for i in range(num_iters):
        h = predict(X, theta)
        error = h - y
        gradient = (1 / m) * np.dot(X.T, error)
        theta -= alpha * gradient
        J_history.append(cost_function(X, y, theta))

    return theta, J_history


theta_initial = np.zeros((X.shape[1], 1))


learning_rate = 0.01
num_iterations = 1000


theta_trained, cost_history = gradient_descent(X, y, theta_initial, learning_rate, num_iterations)

print("Trained parameters:")
print(theta_trained)
